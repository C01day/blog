---
layout: post
title: 机器学习笔记
subtitle: 或许哪天就忘了呢？
author: "C01day"
date: 2021-09-13
header_style: image # text
header_img: /img/in-post/cover/119.jpg
catalog: true
tags:
  - 笔记
---

## 线性回归的代价函数

$$
J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2
$$

::: info
代价函数$J(\theta)$是关于$\theta_1,\theta_2,...,\theta_n$的函数

$h_\theta(x)=\theta^Tx=\theta_0x_0+\theta_1x_1+\cdots+\theta_nx_n$

$x^{(i)}$表示第$i$个样本
:::

## 梯度下降

通过梯度下降，找到$J(\theta)$的局部最优解

$repeat\;until\;convergence:$

$$
\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)
$$

::: info
$\alpha:$学习率

注意所有的$\theta$是同时更新的
:::

## Logistic 回归

$$
\left.
\begin{array}{lr}
h_\theta(x)=g(\theta^Tx) \\
g(z)=\frac{1}{1+e^{-z}}
\end{array}
\right\}
\Rightarrow h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}
$$
![](https://i.loli.net/2021/09/13/GsRKOIfkLnrAxC6.png)

### Logistic 回归的代价函数

$$
J(\theta)=\frac{1}{m}\sum_{i=1}^{m}Cost(h_\theta(x),y)
$$

$$
Cost(h_\theta(x),y)=
\left\{
\begin{array}{lr}
-\log(h_\theta(x)) \quad y=1 \\
-\log(1-h_\theta(x)) \quad y=0
\end{array}
\right.
$$

![](https://i.loli.net/2021/09/13/KnxBR2GUAP58VIr.png)

$P(y=1|x;\theta)$表示给定$x,\theta$后$y=1$的概率

假设预测$y=1$的概率$h_\theta(x)=1$，而$y$的真实值是$1$，那选用第一个代价函数，此时$Cost$为$0$；如果$y$的真实值是$0$，那选用第二个代价函数，此时$Cost$为$\infty$。

将$Cost$合并简化：
$$
J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^my^{(i)}\log h_\theta(x^{(i)})+(1-y^{(i)})\log(1-h_\theta(x^{(i)}))\right]
$$
### 多元分类
![](https://i.loli.net/2021/09/13/KzeWLTQxs24rg9G.png)

对于每个$Class\;i$，将其转化为二分类问题，用上述$Logistic$回归的代价函数$J(\theta)$，结合梯度下降，训练各自的分类器$h_\theta^{(i)}(x)$，用来预测$y=i$时的概率

$$
h_\theta^{(i)}(x)=P(y=i|x;\theta) \quad (i=1,2,3\dots)
$$

对于一个新的输入$x$，找到最大的$h_\theta^{(i)}(x)$即可，此时的$i$便是预测的类。

::: info
不同的$h_\theta^{(i)}(x)$有不同的参数$\theta$
:::

## 正则化代价函数
正则化线性回归的代价函数：
$$
J(\theta)=\frac{1}{2m}\left[\;\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\underbrace{\lambda\sum_{j=1}^n\theta_j^2}_{Ragularization}\;\right]
$$

::: info
$m:$训练集样本容量

$n:$参数个数

正则化项是为了使参数$\theta$尽量地小，保证假设模型相对简单，避免过拟合
:::

正则化逻辑回归的代价函数和上述类似，加一个正则化项$\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$。

## 神经网络
![](https://i.loli.net/2021/09/14/eOYQAIiX21JlpVR.png)

$\Theta_{ij}^{(k)}:$右上角的$(k)$表示神经网络第$k$层与第$k+1$层之间的参数（或者说权重），右下角的$ij$表示$a_i^{k+1}$的$i$和$x_j$的$j$。

### 多元分类

![](https://i.loli.net/2021/09/15/8hsXFRyvDWIz25u.png)

图中是一个四分类问题，训练集$(x^{(i)},y^{(i)})$，其中$x^{(i)}$表示图片的特征，$y^{(i)}$是一个四维的标签，我们想要让$h_\Theta(x^{(i)})\approx y^{(i)}$。

### 代价函数

![](https://i.loli.net/2021/09/15/xCQqBs1kRtZuDhg.png)

和逻辑回归的代价函数类似，逻辑回归的代价函数$J(\theta)$（经过正则化）是

$$
J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^my^{(i)}\log h_\theta(x^{(i)})+(1-y^{(i)})\log(1-h_\theta(x^{(i)}))\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
$$

神经网络的代价函数$J(\Theta)$是

$$
J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^m\sum_{k=1}^Ky_k^{(i)}\log (h_\Theta(x^{(i)}))_k+(1-y_k^{(i)})\log(1-(h_\Theta(x^{(i)}))_k)\right]+\frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2
$$

::: info
$L:$神经网络层数

$s_l:$第$l$层的神经元个数（不包括偏置单元）

$K$代表输出层的单元数，等价于$s_L$

$h_\Theta(x)$是一个$K$维向量，$(h_\Theta(x))_i$表示输出向量的第$i$个值
:::

### 反向传播

![](https://i.loli.net/2021/09/15/t7hqs9JPWTVDedY.png)

一开始让$\Delta_{ij}^{(l)}=0$，用来计算$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$

遍历训练集的每个样本$(x^{(i)},y^{(i)})$

首先让输入层的激活函数$a^{(1)}=x^{(i)}$

运用正向传播算法

$$
z^{(l+1)}=\Theta^{(l)}a^{(l)} \\
a^{(l+1)}=g(z^{(l+1)})
$$

计算之后每层的激活函数$a^{(l)}\;(l=2,3,\dots,L)$

然后用样本的标签（或者说真值）$y^{(i)}$，计算输出值的误差项$\delta^{(L)}=a^{(L)}-y^{(i)}$

运用反向传播算法

$$
\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.\ast \underbrace{g'(z^{(l)})}_{a^{(l)}.\ast(1-a^{(l)})}
$$

计算$\delta^{(l)}\;(l=L-1,L-2,\dots,2)$，注意没有$\delta^{(1)}$，因为不需要对输入层考虑误差项

最后让$\Delta_{ij}^{(l)}:=\Delta_{ij}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$，或者写成向量形式$\Delta^{(l)}:=\Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T$

由此计算出

$$
D_{ij}^{(l)}:=
\left\{
\begin{array}{lr}
\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)} \quad if \; j \neq 0 \\
\frac{1}{m}\Delta_{ij}^{(l)} \quad if \; j = 0
\end{array}
\right.
$$

而我们所需要的偏导$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=D_{ij}^{(l)}$

得到了神经网络的代价函数关于每个参数$\Theta_{ij}^{(l)}$的偏导项后，就可以使用梯度下降或者其他高级优化算法了。

::: info
$.\ast$表示点乘，为矩阵的对应位置相乘
:::

### 梯度检测

反向传播算法可能会出现错误，因此需要用梯度检测来检验偏导，看是否近似

$$
\frac{J(\dots,\Theta_{ij}^{(l)}+\epsilon,\dots)-J(\dots,\Theta_{ij}^{(l)}-\epsilon,\dots)}{2\epsilon}\approx\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=D_{ij}^{(l)}
$$

::: info
由于计算量非常大，因此在训练分类器之前，需要关掉梯度检测
:::

### 随机初始化

如果将所有参数都初始化为0，会造成所有单元都相等的现象。为了避免这种情况，需要对参数进行随机初始化

$$
initialize \; each \; \Theta_{ij}^{(l)} to \; a \; random \; value \; in \; [-\epsilon,+\epsilon]
$$

## 训练集、验证集、测试集

先使用测试集对不同的假设模型$i$得到参数$\theta^{(i)}$

$$
\min_{\theta^{(i)}} J_{train}(\theta^{(i)})
$$

再用验证集选择出交叉验证误差最小的模型$i$

$$
\min_i J_{cv}(\theta^{(i)})
$$

然后用测试集计算泛化误差

$$
J_{test}(\theta^{(i)})
$$

## 偏差和方差

### 模型多项式次数$d$与偏差、方差

![](https://i.loli.net/2021/09/17/TsbuJwflKcOaRVe.png)

如果训练集误差$J_{train}(\theta)$高，验证集误差$J_{cv}(\theta)$也高（图中左侧红框），则是一个偏差问题$(bias)$；

如果训练集误差$J_{train}(\theta)$低，但验证集误差$J_{cv}(\theta)$高（图中右侧红框），则是一个方差问题$(variance)$。

### 正则化参数$\lambda$与偏差、方差

![](https://i.loli.net/2021/09/17/BMZExFULsgp3zrq.png)

::: info
图中，$J(\theta)$包括正则化项，而$J_{train}(\theta),J_{cv}(\theta)$不包括
:::

通过取不同的$\lambda$值，让$J(\theta)$最小

$$
\min_{\theta} J(\theta)
$$

得到对应的参数$\theta$，计算在参数$\theta$下$J_{train}(\theta),J_{cv}(\theta)$的变化

$\lambda$越小，惩罚程度越小，正则化项可以忽略，可能会出现过拟合现象（正则化是为了防止过拟合现象），即对训练集的拟合效果非常好，此时$J_{train}(\theta)$很小；$\lambda$越大，惩罚程度越大，可能连训练集都不能很好地拟合，此时$J_{train}(\theta)$很大。

同理，在$\lambda$很小时，可能会出现过拟合现象，对应高方差问题$(variance)$，因此$J_{cv}(\theta)$较大；在$\lambda$很大时，可能会出现欠拟合现象，对应高偏差问题$(bias)$，因此$J_{cv}(\theta)$也较大。而中间总会有某个$\lambda$值，此时的表现刚好合适。

::: info
过拟合对应高方差问题$(variance)$，$J_{train}(\theta)$较小，但$J_{cv}(\theta)$较大；

欠拟合对应高偏差问题$(bias)$，$J_{train}(\theta)$和$J_{cv}(\theta)$都较大。

上述图像比较简单和理想化，真实数据可能更加凌乱且有很多噪声，但趋势总归是正确的
:::

## 精确度和召回率

![](https://i.loli.net/2021/09/18/SRcXWL2v3bqr5PK.png)

$precision:$预测为1的数据中实际为1的比例
$$
\dfrac{true\;positive}{predicted\;positive}=\dfrac{true\;positive}{true\;positive+false\;positive}
$$

$recall:$实际为1的数据中真正被预测为1的比例
$$
\dfrac{true\;positive}{actual\;positive}=\dfrac{true\;positive}{true\;positive+false\;negative}
$$

### 精确度和召回率的权衡

![](https://i.loli.net/2021/09/18/VHvI1Z69fFzYl3b.png)

通过改变$threshold$，精确度和召回率会变化。具体来说，当$threshold$增大时，会有更高的精确度（预测为1的数据中实际为1的比例更大）和更低的召回率（实际为1的数据不变，但由于更加保守，预测为1的数据变少了）；当$threshold$减小时，会有更低的精确度和更高的召回率。

两者不可兼得，可以使用$\;F score\;$来评估算法（当然，也有很多其他评估方式）

$$
F \; score=2\dfrac{PR}{P+R}
$$

$P:precision \quad R:recall$

## 支持向量机

### 代价函数

支持向量机的代价函数和逻辑回归的代价函数类似

![](https://i.loli.net/2021/09/21/LkI9xZaB5SlpzOK.png)

![](https://i.loli.net/2021/09/24/ZCPoVwcB4Jn5suY.png)

$$
J(\theta)=\min_{\theta} C \sum_{i=1}^{m}\left[ y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)}) \right] + \frac{1}{2}\sum_{i=1}^{n}\theta_j^2
$$

其中，$cost_1,cost_0$和$h_\theta(x)$类似，前者是分段直线，后者是曲线（参考上图）

同时，去掉了参数$\frac{1}{m}$，并从原来的$A+\lambda B$形式变为了$CA+B$形式

当$y=1$时，我们希望$\theta^Tx$不仅仅是$\geq0$，而是$\geq1$，这样$cost_1$为$0$，$A$项就为$0$，使代价函数尽量小，反之$y=0$时希望$\theta^Tx<-1$。

当得到了使代价函数$J(\theta)$最小的参数$\theta$后，带入交叉验证集/测试集的数据$x$，就能得到支持向量机的输出$h_\theta(x)$

$$
h_\theta(x)=
\left\{
\begin{array}{lr}
1 \quad if \quad \theta^T x \geq 0 \\
0 \quad if \quad \theta^T x < 0
\end{array}
\right.
$$

### 非线性决策边界

$Predict \; y=1 \; if$

$$
\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+\dotsb\geq0
$$

以高斯核函数为例，给定一个输入$x$，得到

$$
f_i=k(x,l^{(i)})=exp\left(-\dfrac{\parallel x-l^{(i)} \parallel^2}{2\sigma^2}\right)
$$

其中，$l^{(i)}$是标记点，等同于训练样本点（$l^{(i)}=x^{(i)}$）；$x$可以是训练集，交叉验证集，测试集等等。

如果$x\approx l^{(i)},f_i\approx 1;$ 如果$x$距离$l^{(i)}$很远，则$f_i\approx 0$，可以理解为相似度。

![](https://i.loli.net/2021/09/26/xcEojV6wNh1uIlH.png)

如图所示，靠近$l^{(1)},l^{(2)}$的点将会预测为$1$，远离则为$0$。

### 核函数与$SVM$

对于训练样本$(x^{(i)},y^{(i)})$，可以得到$m$个$f_{j}^{(i)}=k(x^{(i)},l^{(j)})$，即

$$
f^{(i)}=\left[f_{1}^{(i)},f_{2}^{(i)},\dotsb,f_{m}^{(i)}\right]^T
$$

$m$为训练样本的大小，因为$l^{(j)}$标记点就是训练样本点，所以$l^{(j)}$标记点有$m$个，$f^{(i)}$为$m$维向量。

![](https://i.loli.net/2021/09/26/zLhogBZlAJTm5cv.png)

将$x^{(i)}$映射为$f^{(i)}$（描述第$i$个训练样本的特征向量由$x^{(i)}$变成$f^{(i)}$），则$\theta^Tx^{(i)}$变为$\theta^Tf^{(i)}$。

::: info
$\theta^Tx^{(i)}$和$\theta^Tf^{(i)}$中的$x$（$n$维）和$f$（$m$维）的维度不一定相等，对应的$\theta$维度也不一样。其中，$n$是特征的维度，$m$是训练样本大小

同样，正则化项$\sum_{j=1}^n\theta_j^2$中的$n$等于$\theta$的维度，由于图中的$f^{(i)}$为$m$维向量，$\theta$则也为$m$维向量，正则化项中的$n$其实就等于$m$
:::

## 主成分分析$PCA$

![](https://i.loli.net/2021/09/27/DiYS8WtrBgExeN4.png)

假如要将$2$维降成$1$维，则找出使得投影误差最小的向量$u$，即点到投影后的点之间的距离。

要将$n$维降成$k$维，则找出使得投影误差最小的$k$个向量$u^{(1)},u^{(2)},\dotsb,u^{(k)}$。

![](https://i.loli.net/2021/09/27/6P3VR7neuW4jpCT.png)

同时，主成分分析$PCA$与线性回归不同，如上图所示，左边是线性回归，右边是$PCA$，蓝色线段代表各自的误差，两者的误差并不相同。

### 主成分分析算法

将数据从$n$维降到$k$维

- 首先计算协方差矩阵$Sigma$

$$
Sigma=\frac{1}{m}\sum_{i=1}^{n}(x^{(i)})(x^{(i)})^T
$$

$x^{(i)}\in\R^{n \times 1},Sigma\in\R^{n \times n}$

- 然后计算$Sigma$的特征向量矩阵$U$

$$
U=
  \begin{bmatrix}
   u^{(1)} & u^{(2)} & \dotsb & u^{(n)}
  \end{bmatrix}
\in\R^{n \times n}
$$

$u^{(i)}\in\R^{n \times 1}$

- 取前$k$个向量组成$U_{reduce}$

$$
U_{reduce}=
  \begin{bmatrix}
   u^{(1)} & u^{(2)} & \dotsb & u^{(k)}
  \end{bmatrix}
\in\R^{n \times k}
$$

- 对于一个样本$x^{(i)}\in\R^{n \times 1}$，降维后新的坐标$z^{(i)}\in\R^{k \times 1}$

$$
z^{(i)}=[U_{reduce}]^T x^{(i)}=
  \begin{bmatrix}
  (u^{(1)})^T \\ 
  (u^{(2)})^T \\
  \dotsb \\ 
  (u^{(k)})^T
  \end{bmatrix}
x^{(i)}=
\R^{k \times n} \times \R^{n \times 1}
\in\R^{k \times 1}
$$

## 异常检测

### 原始模型

![](https://i.loli.net/2021/09/29/fAvb1kFUi69xP34.png)

训练集为$\{x^{(1)},x^{(2)},\dotsb,x^{(m)}\}$，样本$i$有$n$个特征$\{x^{(i)}_1,x^{(i)}_2,\dotsb,x^{(i)}_n \}$

每一种特征$x_j$都满足正态分布，计算参数$\mu_1,\dotsb,\mu_n,\sigma^2_1,\dotsb,\sigma^2_n$

特征$j$的平均值$\mu_j:$

$$
\mu_j=\frac{1}{m}\sum_{i=1}^{m}x^{(i)}_j
$$

特征$j$的方差$\sigma^2_j:$

$$
\sigma^2_j=\frac{1}{m}\sum_{i=1}^{m}(x^{(i)}_j-\mu_j)^2
$$

然后对于一个新的特征向量$x$，计算$p(x)$概率

$$
p(x)=\prod_{j=1}^{n}p(x_j;\mu_j,\sigma^2_j)
$$

如果概率$p(x)<\epsilon$，则$x$是不正常的样本

::: info
$p(x_j;\mu_j,\sigma^2_j):$参数为$\mu_j,\sigma^2_j$的正态分布在$x_j$位置的概率
:::

### 多元高斯模型

不再将多个特征视作独立分开的高斯分布，而是将$p(x)$看作一个多元高斯分布，参数$\mu\in\R^{n}$，协方差矩阵$\Sigma\in\R^{n \times n}$

![](https://i.loli.net/2021/10/08/yj51vZPalX8zoR2.png)

## 协同过滤算法

以电影评分为例，电影$i$的特征为$x^{(i)}$，能够描述电影的特点；用户$j$的参数为$\theta^{(j)}$。$(\theta^{(j)})^T x^{(i)}$表示用户$j$对电影$i$的预测评分。

![](https://i.loli.net/2021/10/11/aCQNwAustXRJrGv.png)

给出$x$，能通过代价函数预测$\theta$；反之，给出$\theta$，能通过代价函数预测$x$。

其中，$r(i,j)=1$表示用户$j$评价了电影$i$，$y^{(i,j)}$表示用户$j$对电影$i$的实际评分。

协同过滤算法能同时最小化参数$x$和$\theta$，其代价函数为上图中前两个代价函数的组合。

首先将参数初始化为较小的随机值（和神经网络类似），通过梯度下降等方法将代价函数最小化，可以得到参数$x$和$\theta$。如果用户$j$尚未评价电影$i$，可以通过$(\theta^{(j)})^T x^{(i)}$计算出预测的评分。

